{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Para versão recente do python\n",
    "!pip install tensorflow==2.8.0 tensorflow-gpu==2.8.0 opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para versões antigas - https://www.python.org/ftp/python/3.7.4/\n",
    "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python==4.5.2.54 mediapipe==0.8.5 sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MediaPipe solutions - reconhecimento e desenho dos pontos na mão\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    \"\"\" \n",
    "    Funcao com objetivo de aplicar a previsao de reconhecimento na imagem desejada \n",
    "    Recebe imagem (frame da webcam) e um modelo que sera responsavel pela previsão\n",
    "    Retorna o frame utilizado e a previsao feita pelo modelo\n",
    "    A conversao da imagem se faz necessaria para ser tratada pelo modelo (BGR -> RGB)\n",
    "    A mudanca na propriedade de leitura tem como objetivo salvar memoria\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    \"\"\"\n",
    "    Funcao que recebe uma imagem (frame) junto com as previsoes feitas pelo modelo e aplica\n",
    "    sob a imagem o desenho dos pontos necessarios (nao ha motivo para devolver a imagem pois ela\n",
    "    ja e alterada diretamente).\n",
    "    \"\"\"\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results, auto=False, axis=None, value=None):\n",
    "    if auto:\n",
    "        if axis == 'x':\n",
    "            pose = np.array([[res.x+value, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "            face = np.array([[res.x+value, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "            lh = np.array([[res.x+value, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "            rh = np.array([[res.x+value, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "        elif axis == 'y':\n",
    "            pose = np.array([[res.x, res.y+value, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "            face = np.array([[res.x, res.y+value, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "            lh = np.array([[res.x, res.y+value, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "            rh = np.array([[res.x, res.y+value, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "        #elif axis == 'z':\n",
    "        #    pose = np.array([[res.x, res.y, res.z+value, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "        #    face = np.array([[res.x, res.y, res.z+value] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "        #    lh = np.array([[res.x, res.y, res.z+value] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "        #    rh = np.array([[res.x, res.y, res.z+value] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "        else:\n",
    "            auto = False\n",
    "    else:\n",
    "        pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "        face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "        lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "        rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho que guarda o numpy array com os pontos extraidos\n",
    "DATA_PATH = os.path.join('MP_Data')\n",
    "\n",
    "# Sinais que serão detectados\n",
    "actions = np.array(['ola', 'obrigado', 'teamo'])\n",
    "\n",
    "# Representa a quantidade de sequências de frames que tem os dados\n",
    "no_sequences = 30\n",
    "\n",
    "# Representa a quantidade de frames que cada sequência possui\n",
    "sequence_lenght = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria pastas para cada sinal definido\n",
    "# Cada pasta tem 30 pastas representando os videos modelo do sinal\n",
    "# Cada vídeo contém 30 frames e cada frame 1662 pontos extraidos\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try: # Cria pastas e subpastas\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except: # Caso já exista passa para próxima pasta\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENTATIVA DE FAZER O PROGRAMA SIMULAR ENTRADAS    \n",
    "\n",
    "#Acessa a webcam - valor (0) representa o hardware\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Define o modelo utilizado\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    # Extrai os frames de cada video para cada ação\n",
    "    for action in actions:\n",
    "        for frame_num in range(sequence_lenght):\n",
    "            #Seleciona o frame atual da webcam\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            #Processa previsoes\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            #print(results)\n",
    "            #Desenha os pontos\n",
    "            draw_landmarks(image, results)\n",
    "                \n",
    "            if frame_num == 0:    \n",
    "                #Textos para indicar inicio de gravação\n",
    "                cv2.putText(image, \"INICIANDO GRAVAÇÃO DE SINAL\", \n",
    "                (120, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "                \n",
    "                cv2.putText(image, \"Gravando para {} Frame: {}\".format(action, frame_num), \n",
    "                (15, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                \n",
    "                # Tempo de espera entre um vídeo e outro\n",
    "                cv2.waitKey(2000)\n",
    "            else:\n",
    "                cv2.putText(image, \"Gravando para {} Frame: {}\".format(action, frame_num), \n",
    "                (15, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                \n",
    "            # Extrai os pontos de um frame e salva como um arquivo .npy (numpy array)\n",
    "            for sequence in range(no_sequences):\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                if sequence < (no_sequences/2):\n",
    "                    value_n = sequence*0.01\n",
    "                    keypoints = extract_keypoints(results, auto=True, axis='x', value=value_n)\n",
    "                elif sequence < (no_sequences):\n",
    "                    value_n = (sequence-(no_sequences/2))*0.01\n",
    "                    keypoints = extract_keypoints(results, auto=True, axis='y', value=value_n)\n",
    "                np.save(npy_path, keypoints)\n",
    "                    \n",
    "                \n",
    "            #Faz o display do frame\n",
    "            if ret == True: \n",
    "                cv2.imshow('Webcam', image)\n",
    "                #Encerra a webcam \n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports que serão importante para treinar o modelo e nomear os dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "sequences, labels = [], []\n",
    "\n",
    "# Carrega e adiciona todos os pontos de uma sequência no array sequences\n",
    "# Enquanto o array labels coloca em ordem o valor de determinada ação com certa sequencia\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_lenght):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence),'{}.npy'.format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "    \n",
    "    matrix_labels = to_categorical(labels).astype(int)\n",
    "    X = np.array(sequences)\n",
    "    \n",
    "    # Com os dados já definidos é possível separar uma quantidade para teste e treinamento do modelo\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, matrix_labels, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports para construção da rede neural\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do caminho para registro de logs da rede\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup da rede neural\n",
    "model = Sequential()\n",
    "\n",
    "# Cada função add adiciona uma layer para a rede\n",
    "# O parâmetro return_sequences é importante para passar para próxima layer de forma ordenada\n",
    "# O parâmetro activation define a função que será utilizada para ativar os neurônios\n",
    "#  O parâmetro input_shape = 30 frames cada um com 1662 pontos reconhecidos\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662))) \n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Última camada possui a quantidades de pontos definido pela quantidade de ações\n",
    "# A função softmax entrega um resultado com a probabilidade de cada ação (será selecionado a com maior probabilidade)\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "3/3 [==============================] - 6s 569ms/step - loss: 4.6893 - categorical_accuracy: 0.3639\n",
      "Epoch 2/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 6.7608 - categorical_accuracy: 0.2760\n",
      "Epoch 3/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 2.0025 - categorical_accuracy: 0.2897\n",
      "Epoch 4/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 1.1671 - categorical_accuracy: 0.3386\n",
      "Epoch 5/2000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 1.0937 - categorical_accuracy: 0.3659\n",
      "Epoch 6/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.1061 - categorical_accuracy: 0.3347\n",
      "Epoch 7/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 1.1002 - categorical_accuracy: 0.2642\n",
      "Epoch 8/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.0985 - categorical_accuracy: 0.3190\n",
      "Epoch 9/2000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.0980 - categorical_accuracy: 0.3170\n",
      "Epoch 10/2000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.0956 - categorical_accuracy: 0.3308\n",
      "Epoch 11/2000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.0918 - categorical_accuracy: 0.4834\n",
      "Epoch 12/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.0864 - categorical_accuracy: 0.4989\n",
      "Epoch 13/2000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 1.0674 - categorical_accuracy: 0.3972\n",
      "Epoch 14/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.9965 - categorical_accuracy: 0.3464\n",
      "Epoch 15/2000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.0055 - categorical_accuracy: 0.5108\n",
      "Epoch 16/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.9771 - categorical_accuracy: 0.4931\n",
      "Epoch 17/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.0598 - categorical_accuracy: 0.4345\n",
      "Epoch 18/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.0411 - categorical_accuracy: 0.3953\n",
      "Epoch 19/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.9836 - categorical_accuracy: 0.3112\n",
      "Epoch 20/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.9489 - categorical_accuracy: 0.3993\n",
      "Epoch 21/2000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 1.0462 - categorical_accuracy: 0.6555\n",
      "Epoch 22/2000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.0980 - categorical_accuracy: 0.3170\n",
      "Epoch 23/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.0982 - categorical_accuracy: 0.3561\n",
      "Epoch 24/2000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.1080 - categorical_accuracy: 0.3053\n",
      "Epoch 25/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.1028 - categorical_accuracy: 0.3053\n",
      "Epoch 26/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.0946 - categorical_accuracy: 0.3249\n",
      "Epoch 27/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 1.0903 - categorical_accuracy: 0.3308\n",
      "Epoch 28/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0835 - categorical_accuracy: 0.5264\n",
      "Epoch 29/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.0732 - categorical_accuracy: 0.6204\n",
      "Epoch 30/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 1.0557 - categorical_accuracy: 0.5479\n",
      "Epoch 31/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.0217 - categorical_accuracy: 0.4384\n",
      "Epoch 32/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.9746 - categorical_accuracy: 0.4011\n",
      "Epoch 33/2000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.9880 - categorical_accuracy: 0.4403\n",
      "Epoch 34/2000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.0448 - categorical_accuracy: 0.5909\n",
      "Epoch 35/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 1.0701 - categorical_accuracy: 0.4481\n",
      "Epoch 36/2000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 1.0551 - categorical_accuracy: 0.5108\n",
      "Epoch 37/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.9876 - categorical_accuracy: 0.6457\n",
      "Epoch 38/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.9823 - categorical_accuracy: 0.2994\n",
      "Epoch 39/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.9376 - categorical_accuracy: 0.6047\n",
      "Epoch 40/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.9372 - categorical_accuracy: 0.6438\n",
      "Epoch 41/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8534 - categorical_accuracy: 0.5519\n",
      "Epoch 42/2000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.8361 - categorical_accuracy: 0.5812\n",
      "Epoch 43/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.7936 - categorical_accuracy: 0.5226\n",
      "Epoch 44/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.9434 - categorical_accuracy: 0.5949\n",
      "Epoch 45/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.9375 - categorical_accuracy: 0.5676\n",
      "Epoch 46/2000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.8590 - categorical_accuracy: 0.6204\n",
      "Epoch 47/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7865 - categorical_accuracy: 0.5989\n",
      "Epoch 48/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.6237 - categorical_accuracy: 0.6516\n",
      "Epoch 49/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.5796 - categorical_accuracy: 0.6927\n",
      "Epoch 50/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.6420 - categorical_accuracy: 0.6497\n",
      "Epoch 51/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5862 - categorical_accuracy: 0.6438\n",
      "Epoch 52/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.5166 - categorical_accuracy: 0.6399\n",
      "Epoch 53/2000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.5836 - categorical_accuracy: 0.6947\n",
      "Epoch 54/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.5752 - categorical_accuracy: 0.7456\n",
      "Epoch 55/2000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.5441 - categorical_accuracy: 0.7554\n",
      "Epoch 56/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.5575 - categorical_accuracy: 0.6517\n",
      "Epoch 57/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.5599 - categorical_accuracy: 0.7162\n",
      "Epoch 58/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.5452 - categorical_accuracy: 0.7162\n",
      "Epoch 59/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.5395 - categorical_accuracy: 0.6380\n",
      "Epoch 60/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.6316 - categorical_accuracy: 0.6048\n",
      "Epoch 61/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5907 - categorical_accuracy: 0.6987\n",
      "Epoch 62/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.5802 - categorical_accuracy: 0.7437\n",
      "Epoch 63/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5058 - categorical_accuracy: 0.7827\n",
      "Epoch 64/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.5457 - categorical_accuracy: 0.6909\n",
      "Epoch 65/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.5451 - categorical_accuracy: 0.6869\n",
      "Epoch 66/2000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.5861 - categorical_accuracy: 0.6438\n",
      "Epoch 67/2000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.5392 - categorical_accuracy: 0.6947\n",
      "Epoch 68/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5410 - categorical_accuracy: 0.7455\n",
      "Epoch 69/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.5148 - categorical_accuracy: 0.8023\n",
      "Epoch 70/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.4892 - categorical_accuracy: 0.7866\n",
      "Epoch 71/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.5363 - categorical_accuracy: 0.6869\n",
      "Epoch 72/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.6300 - categorical_accuracy: 0.5754\n",
      "Epoch 73/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5282 - categorical_accuracy: 0.8023\n",
      "Epoch 74/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5427 - categorical_accuracy: 0.6908\n",
      "Epoch 75/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.5637 - categorical_accuracy: 0.6341\n",
      "Epoch 76/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5963 - categorical_accuracy: 0.6400\n",
      "Epoch 77/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.5336 - categorical_accuracy: 0.6986\n",
      "Epoch 78/2000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.5451 - categorical_accuracy: 0.7122\n",
      "Epoch 79/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5690 - categorical_accuracy: 0.6693\n",
      "Epoch 80/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.5952 - categorical_accuracy: 0.6204\n",
      "Epoch 81/2000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.7095 - categorical_accuracy: 0.6398\n",
      "Epoch 82/2000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.8262 - categorical_accuracy: 0.2271\n",
      "Epoch 83/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.0465 - categorical_accuracy: 0.3601\n",
      "Epoch 84/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0766 - categorical_accuracy: 0.4972\n",
      "Epoch 85/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.9884 - categorical_accuracy: 0.6477\n",
      "Epoch 86/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.9484 - categorical_accuracy: 0.6438\n",
      "Epoch 87/2000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.8829 - categorical_accuracy: 0.6165\n",
      "Epoch 88/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.7959 - categorical_accuracy: 0.6341\n",
      "Epoch 89/2000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.7142 - categorical_accuracy: 0.6341\n",
      "Epoch 90/2000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.7721 - categorical_accuracy: 0.6263\n",
      "Epoch 91/2000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.7521 - categorical_accuracy: 0.7025\n",
      "Epoch 92/2000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.6962 - categorical_accuracy: 0.6595\n",
      "Epoch 93/2000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.5869 - categorical_accuracy: 0.6556\n",
      "Epoch 94/2000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.6692 - categorical_accuracy: 0.6751\n",
      "Epoch 95/2000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.5532 - categorical_accuracy: 0.6261\n",
      "Epoch 96/2000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.5951 - categorical_accuracy: 0.6595\n",
      "Epoch 97/2000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.6376 - categorical_accuracy: 0.7202\n",
      "Epoch 98/2000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.5645 - categorical_accuracy: 0.7338\n",
      "Epoch 99/2000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.5772 - categorical_accuracy: 0.7241\n",
      "Epoch 100/2000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.5443 - categorical_accuracy: 0.7123\n",
      "Epoch 101/2000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.5981 - categorical_accuracy: 0.6732\n",
      "Epoch 102/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.5763 - categorical_accuracy: 0.7613\n",
      "Epoch 103/2000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.4984 - categorical_accuracy: 0.7886\n",
      "Epoch 104/2000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.5832 - categorical_accuracy: 0.7574\n",
      "Epoch 105/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.5370 - categorical_accuracy: 0.7867\n",
      "Epoch 106/2000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.5051 - categorical_accuracy: 0.8238\n",
      "Epoch 107/2000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.5369 - categorical_accuracy: 0.7691\n",
      "Epoch 108/2000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.5129 - categorical_accuracy: 0.7965\n",
      "Epoch 109/2000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.5030 - categorical_accuracy: 0.8317\n",
      "Epoch 110/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.4865 - categorical_accuracy: 0.7983\n",
      "Epoch 111/2000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.5255 - categorical_accuracy: 0.7847\n",
      "Epoch 112/2000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.5064 - categorical_accuracy: 0.8141\n",
      "Epoch 113/2000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.5374 - categorical_accuracy: 0.7828\n",
      "Epoch 114/2000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.4424 - categorical_accuracy: 0.8160\n",
      "Epoch 115/2000\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.4237 - categorical_accuracy: 0.8160\n",
      "Epoch 116/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.4487 - categorical_accuracy: 0.8141\n",
      "Epoch 117/2000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.4243 - categorical_accuracy: 0.8102\n",
      "Epoch 118/2000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3796 - categorical_accuracy: 0.8689\n",
      "Epoch 119/2000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.4395 - categorical_accuracy: 0.8415\n",
      "Epoch 120/2000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3260 - categorical_accuracy: 0.8747\n",
      "Epoch 121/2000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.6169 - categorical_accuracy: 0.7163\n",
      "Epoch 122/2000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3448 - categorical_accuracy: 0.8610\n",
      "Epoch 123/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3395 - categorical_accuracy: 0.8630\n",
      "Epoch 124/2000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3534 - categorical_accuracy: 0.8669\n",
      "Epoch 125/2000\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.3533 - categorical_accuracy: 0.8689\n",
      "Epoch 126/2000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2898 - categorical_accuracy: 0.8728\n",
      "Epoch 127/2000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.6545 - categorical_accuracy: 0.6908\n",
      "Epoch 128/2000\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.7350 - categorical_accuracy: 0.6538\n",
      "Epoch 129/2000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.5807 - categorical_accuracy: 0.7633\n",
      "Epoch 130/2000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.5042 - categorical_accuracy: 0.7907\n",
      "Epoch 131/2000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.4524 - categorical_accuracy: 0.8434\n",
      "Epoch 132/2000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3900 - categorical_accuracy: 0.9237\n",
      "Epoch 133/2000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.4063 - categorical_accuracy: 0.8826\n",
      "Epoch 134/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.5310 - categorical_accuracy: 0.7651\n",
      "Epoch 135/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.4100 - categorical_accuracy: 0.8415\n",
      "Epoch 136/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3876 - categorical_accuracy: 0.8572\n",
      "Epoch 137/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3754 - categorical_accuracy: 0.8552\n",
      "Epoch 138/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.4041 - categorical_accuracy: 0.8200\n",
      "Epoch 139/2000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2491 - categorical_accuracy: 0.9198\n",
      "Epoch 140/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2604 - categorical_accuracy: 0.9432\n",
      "Epoch 141/2000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2813 - categorical_accuracy: 0.8630\n",
      "Epoch 142/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3150 - categorical_accuracy: 0.8748\n",
      "Epoch 143/2000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2598 - categorical_accuracy: 0.8943\n",
      "Epoch 144/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3172 - categorical_accuracy: 0.8513\n",
      "Epoch 145/2000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.3928 - categorical_accuracy: 0.8179\n",
      "Epoch 146/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.4861 - categorical_accuracy: 0.8415\n",
      "Epoch 147/2000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.6065 - categorical_accuracy: 0.7709\n",
      "Epoch 148/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.3490 - categorical_accuracy: 0.8708\n",
      "Epoch 149/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.6494 - categorical_accuracy: 0.7026\n",
      "Epoch 150/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.6490 - categorical_accuracy: 0.6301\n",
      "Epoch 151/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.6046 - categorical_accuracy: 0.6968\n",
      "Epoch 152/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5434 - categorical_accuracy: 0.7221\n",
      "Epoch 153/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3706 - categorical_accuracy: 0.9236\n",
      "Epoch 154/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.4816 - categorical_accuracy: 0.7045\n",
      "Epoch 155/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3820 - categorical_accuracy: 0.8806\n",
      "Epoch 156/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3554 - categorical_accuracy: 0.9080\n",
      "Epoch 157/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.3366 - categorical_accuracy: 0.8865\n",
      "Epoch 158/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.3357 - categorical_accuracy: 0.9041\n",
      "Epoch 159/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3701 - categorical_accuracy: 0.8747\n",
      "Epoch 160/2000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3145 - categorical_accuracy: 0.9041\n",
      "Epoch 161/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.3410 - categorical_accuracy: 0.8885\n",
      "Epoch 162/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3709 - categorical_accuracy: 0.8649\n",
      "Epoch 163/2000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.4290 - categorical_accuracy: 0.8590\n",
      "Epoch 164/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.3582 - categorical_accuracy: 0.8591\n",
      "Epoch 165/2000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2742 - categorical_accuracy: 0.9217\n",
      "Epoch 166/2000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.3519 - categorical_accuracy: 0.8767\n",
      "Epoch 167/2000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3111 - categorical_accuracy: 0.8924\n",
      "Epoch 168/2000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2196 - categorical_accuracy: 0.9216\n",
      "Epoch 169/2000\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.4448 - categorical_accuracy: 0.8277\n",
      "Epoch 170/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3495 - categorical_accuracy: 0.9119\n",
      "Epoch 171/2000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3660 - categorical_accuracy: 0.8786\n",
      "Epoch 172/2000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.4039 - categorical_accuracy: 0.8317\n",
      "Epoch 173/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.4154 - categorical_accuracy: 0.8141\n",
      "Epoch 174/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3937 - categorical_accuracy: 0.8512\n",
      "Epoch 175/2000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.3390 - categorical_accuracy: 0.8688\n",
      "Epoch 176/2000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3335 - categorical_accuracy: 0.8767\n",
      "Epoch 177/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.4108 - categorical_accuracy: 0.8102\n",
      "Epoch 178/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2705 - categorical_accuracy: 0.9295\n",
      "Epoch 179/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2278 - categorical_accuracy: 0.9295\n",
      "Epoch 180/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2352 - categorical_accuracy: 0.9432\n",
      "Epoch 181/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2440 - categorical_accuracy: 0.9178\n",
      "Epoch 182/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2291 - categorical_accuracy: 0.9432\n",
      "Epoch 183/2000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1613 - categorical_accuracy: 0.9608\n",
      "Epoch 184/2000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1631 - categorical_accuracy: 0.9335\n",
      "Epoch 185/2000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2256 - categorical_accuracy: 0.9315\n",
      "Epoch 186/2000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1870 - categorical_accuracy: 0.9393\n",
      "Epoch 187/2000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1709 - categorical_accuracy: 0.9237\n",
      "Epoch 188/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1908 - categorical_accuracy: 0.9335\n",
      "Epoch 189/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1756 - categorical_accuracy: 0.9432\n",
      "Epoch 190/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1298 - categorical_accuracy: 0.9569\n",
      "Epoch 191/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1636 - categorical_accuracy: 0.9472\n",
      "Epoch 192/2000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1150 - categorical_accuracy: 0.9687\n",
      "Epoch 193/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1909 - categorical_accuracy: 0.9374\n",
      "Epoch 194/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1419 - categorical_accuracy: 0.9491\n",
      "Epoch 195/2000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1975 - categorical_accuracy: 0.9295\n",
      "Epoch 196/2000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2544 - categorical_accuracy: 0.8865\n",
      "Epoch 197/2000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2002 - categorical_accuracy: 0.9198\n",
      "Epoch 198/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1206 - categorical_accuracy: 0.9687\n",
      "Epoch 199/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1145 - categorical_accuracy: 0.9589\n",
      "Epoch 200/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1857 - categorical_accuracy: 0.9315\n",
      "Epoch 201/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2036 - categorical_accuracy: 0.9217\n",
      "Epoch 202/2000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2319 - categorical_accuracy: 0.9354\n",
      "Epoch 203/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1777 - categorical_accuracy: 0.9276\n",
      "Epoch 204/2000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1045 - categorical_accuracy: 0.9628\n",
      "Epoch 205/2000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1118 - categorical_accuracy: 0.9393\n",
      "Epoch 206/2000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2000 - categorical_accuracy: 0.9256\n",
      "Epoch 207/2000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1640 - categorical_accuracy: 0.9315\n",
      "Epoch 208/2000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1146 - categorical_accuracy: 0.9628\n",
      "Epoch 209/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1448 - categorical_accuracy: 0.9296\n",
      "Epoch 210/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1008 - categorical_accuracy: 0.9804\n",
      "Epoch 211/2000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2670 - categorical_accuracy: 0.8963\n",
      "Epoch 212/2000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2292 - categorical_accuracy: 0.9178\n",
      "Epoch 213/2000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3240 - categorical_accuracy: 0.8689\n",
      "Epoch 214/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3647 - categorical_accuracy: 0.8533\n",
      "Epoch 215/2000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3313 - categorical_accuracy: 0.9040\n",
      "Epoch 216/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2849 - categorical_accuracy: 0.8923\n",
      "Epoch 217/2000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2251 - categorical_accuracy: 0.9139\n",
      "Epoch 218/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2177 - categorical_accuracy: 0.8962\n",
      "Epoch 219/2000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3700 - categorical_accuracy: 0.8982\n",
      "Epoch 220/2000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.4479 - categorical_accuracy: 0.5853\n",
      "Epoch 221/2000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.8426 - categorical_accuracy: 0.6184\n",
      "Epoch 222/2000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.7631 - categorical_accuracy: 0.6850\n",
      "Epoch 223/2000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.4891 - categorical_accuracy: 0.8355\n",
      "Epoch 224/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.5046 - categorical_accuracy: 0.7320\n",
      "Epoch 225/2000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.4115 - categorical_accuracy: 0.8336\n",
      "Epoch 226/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.5337 - categorical_accuracy: 0.7691\n",
      "Epoch 227/2000\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3428 - categorical_accuracy: 0.9216\n",
      "Epoch 228/2000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3944 - categorical_accuracy: 0.7516\n",
      "Epoch 229/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3004 - categorical_accuracy: 0.9276\n",
      "Epoch 230/2000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3383 - categorical_accuracy: 0.9413\n",
      "Epoch 231/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2478 - categorical_accuracy: 0.9452\n",
      "Epoch 232/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2546 - categorical_accuracy: 0.9530\n",
      "Epoch 233/2000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2565 - categorical_accuracy: 0.9491\n",
      "Epoch 234/2000\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2081 - categorical_accuracy: 0.9569\n",
      "Epoch 235/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2098 - categorical_accuracy: 0.9452\n",
      "Epoch 236/2000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1845 - categorical_accuracy: 0.9413\n",
      "Epoch 237/2000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1749 - categorical_accuracy: 0.9413\n",
      "Epoch 238/2000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1543 - categorical_accuracy: 0.9569\n",
      "Epoch 239/2000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1283 - categorical_accuracy: 0.9628\n",
      "Epoch 240/2000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1173 - categorical_accuracy: 0.9648\n",
      "Epoch 241/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1311 - categorical_accuracy: 0.9393\n",
      "Epoch 242/2000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1723 - categorical_accuracy: 0.9530\n",
      "Epoch 243/2000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1256 - categorical_accuracy: 0.9550\n",
      "Epoch 244/2000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2108 - categorical_accuracy: 0.9022\n",
      "Epoch 245/2000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1544 - categorical_accuracy: 0.9530\n",
      "Epoch 246/2000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1564 - categorical_accuracy: 0.9491\n",
      "Epoch 247/2000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1159 - categorical_accuracy: 0.9648\n",
      "Epoch 248/2000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1034 - categorical_accuracy: 0.9550\n",
      "Epoch 249/2000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1006 - categorical_accuracy: 0.9628\n",
      "Epoch 250/2000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0961 - categorical_accuracy: 0.9843\n",
      "Epoch 251/2000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0842 - categorical_accuracy: 0.9648\n",
      "Epoch 252/2000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0670 - categorical_accuracy: 0.9843\n",
      "Epoch 253/2000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0679 - categorical_accuracy: 0.9765\n",
      "Epoch 254/2000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0915 - categorical_accuracy: 0.9648\n",
      "Epoch 255/2000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0739 - categorical_accuracy: 0.9765\n",
      "Epoch 256/2000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0678 - categorical_accuracy: 0.9843\n",
      "Epoch 257/2000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0634 - categorical_accuracy: 0.9882\n",
      "Epoch 258/2000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2505 - categorical_accuracy: 0.9217\n",
      "Epoch 259/2000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2460 - categorical_accuracy: 0.8963\n",
      "Epoch 260/2000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2132 - categorical_accuracy: 0.9119\n",
      "Epoch 261/2000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2947 - categorical_accuracy: 0.8923\n",
      "Epoch 262/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.7383 - categorical_accuracy: 0.7905\n",
      "Epoch 263/2000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3276 - categorical_accuracy: 0.8571\n",
      "Epoch 264/2000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2054 - categorical_accuracy: 0.9354\n",
      "Epoch 265/2000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2606 - categorical_accuracy: 0.8983\n",
      "Epoch 266/2000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2861 - categorical_accuracy: 0.8768\n",
      "Epoch 267/2000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1940 - categorical_accuracy: 0.9648\n",
      "Epoch 268/2000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1649 - categorical_accuracy: 0.9589\n",
      "Epoch 269/2000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2037 - categorical_accuracy: 0.9452\n",
      "Epoch 270/2000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1819 - categorical_accuracy: 0.9550\n",
      "Epoch 271/2000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1177 - categorical_accuracy: 0.9784\n",
      "Epoch 272/2000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1136 - categorical_accuracy: 0.9824\n",
      "Epoch 273/2000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1957 - categorical_accuracy: 0.9276\n",
      "Epoch 274/2000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1488 - categorical_accuracy: 0.9550\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8876\\4079260596.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   2334\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2335\u001b[0m     \u001b[1;34m\"\"\"Runs metrics and histogram summaries at epoch end.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2336\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_epoch_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2338\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_log_epoch_metrics\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2383\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2384\u001b[1;33m             \u001b[0msummary_ops_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2385\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2386\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_val_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mas_default\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m    359\u001b[0m       \u001b[1;31m# Flushes the summary writer in eager mode or in graph functions, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[1;31m# not in legacy graph mode (you're on your own there).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m       \u001b[0m_summary_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_flush_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(writer, name)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[0mresource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_summary_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_summary_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py\u001b[0m in \u001b[0;36mflush_summary_writer\u001b[1;34m(writer, name)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 194\u001b[1;33m         _ctx, \"FlushSummaryWriter\", name, writer)\n\u001b[0m\u001b[0;32m    195\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 30, 64)            442112    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 128)           98816     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 596,675\n",
      "Trainable params: 596,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Mostra a performance do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna uma lista com valores de probabilidade de cada ação como definidos no modelo\n",
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva os weights usados pelo modelo\n",
    "model.save('action.h5')\n",
    "#model.load_weights(action.h5)\n",
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('actionAC1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de métricas para aprovação do modelo\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [0, 4]]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "#yhat = model.predict(x_train)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "# Retorna uma matriz bidimensional que representa se houve falsos positivos ou negativos\n",
    "# Quanto maior a quantidade do valor de um lado da matriz melhor o modelo\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retorna a precisão do modelo\n",
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]  #Array que guarda cores\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    \"\"\" Função que mostra na tela a probabilidade de cada um dos sinais, em tempo real.\n",
    "    Recebe os resultados com as probabilidades, os sinais, um frame e as cores a serem utilizadas.\n",
    "    Retorna o mesmo frame com as palavras e suas respectivas probabilidades.\n",
    "    \"\"\"\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):   #Para cada sinal cria os textos e probabilidades\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num] + str(round(res[num],2)), (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence = []      # Guarda os frames\n",
    "sentence = []      # Guarda quais foram as previsões feitas pelo modelo para formar frases \n",
    "predictions = []   # Guarda as prediçoes feita para evitar problemas na transição de sinais\n",
    "threshold = 0.6    # Mínimo para renderizar os resultados, evitando resultados de baixa confiança\n",
    "\n",
    "#Acessa a webcam - valor (0) representa o hardware\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Define o modelo utilizado\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #Seleciona o frame atual da webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #Processa previsoes\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        #Desenha os pontos\n",
    "        #draw_landmarks(image, results)\n",
    "        \n",
    "        #Previsoes\n",
    "        #Pega os pontos que estao aparecendo na camera e inserem em um array\n",
    "        #Cada sequencia é feita com os 30 ultimos frames que depois será passada para o modelo\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        #Verifica se há alguma mão no frame, para só então começar a previsão\n",
    "        rh_onscreen = (sequence[-1][-63:]!=np.zeros(63)).all()\n",
    "        lh_onscreen = (sequence[-1][-126:-63]!=np.zeros(63)).all()\n",
    "        \n",
    "        #if len(sequences)==30:\n",
    "        if len(sequence) == 30 and (rh_onscreen or lh_onscreen):\n",
    "            #expand_dims permite passar uma sequencia por vez\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            #print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "            #Visualização\n",
    "            #Checa se os ultimos 10 frames são do mesmo sinal, para evitar problemas na transição de sinais\n",
    "            if np.unique(predictions[-5:])[0]==np.argmax(res): \n",
    "                predictions = []\n",
    "                #Compara se a probabilidade de certo sinal é maior que o minimo para mostrar\n",
    "                if res[np.argmax(res)] > threshold: #seria possivel fazer a media?\n",
    "                    #tentativa de zerar a sequencia apos previsão correta - ajuda?\n",
    "                    if len(sentence) > 0:\n",
    "                        # Verifica se o sinal já não está incluido na frase\n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            #Caso a frase fique muito grande, guarda apenas os ultimos valores\n",
    "            if len(sentence) > 5:\n",
    "                sentence = sentence[-5:]\n",
    "        \n",
    "            #Renderiza as probabilidades\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "        \n",
    "        #Renderiza predições e a frase\n",
    "        cv2.rectangle(image, (0,0), (640,40), (245,117,16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        #Faz o display do frame\n",
    "        if ret == True: \n",
    "            cv2.imshow('Webcam', image)\n",
    "\n",
    "            #Encerra a webcam \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence[-1][-126:-63].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testearray = np.zeros(1662)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence2 = []\n",
    "for seq in sequence:\n",
    "    sequence2.append(np.zeros(1662))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1662)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequence2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1662)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(np.expand_dims(sequence, axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8321335e-01, 1.5490651e-04, 8.1663173e-01], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
